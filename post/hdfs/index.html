<!DOCTYPE html>
<html lang="en"><meta charset="utf-8"><meta name="generator" content="Hugo 0.69.0" /><meta name="viewport" content="width=device-width,initial-scale=1,viewport-fit=cover">
<meta name="color-scheme" content="light dark">
<meta name="supported-color-schemes" content="light dark"><title>分布式文件系统HDFS&nbsp;&ndash;&nbsp;YHFeio</title><link rel="stylesheet" href="/css/core.min.7a6dedeee7291c9daf16368afd3f5958f3793b2e6f9fa92597ff1df00f09a979724933f1b5bcf4264af992bb6fbee89c.css" integrity="sha384-em3t7ucpHJ2vFjaK/T9ZWPN5Oy5vn6kll/8d8A8JqXlySTPxtbz0Jkr5krtvvuic"><meta name="twitter:card" content="summary" />
<meta name="twitter:title" content="分布式文件系统HDFS" /><body>
    <div class="base-body"><section id="header" class="site header">
    <div class="header wrap"><span class="header left-side"><a class="site home" href="/"><img class="site logo" src="/logo.png" alt /><span class="site name">YHFeio</span></a></span>
        <span class="header right-side"><div class="nav wrap"><nav class="nav"><a class="nav item" href="/categories/">Categories</a><a class="nav item" href="/tags/">Tags</a><a class="nav item" href="/about/">About</a></nav></div></span></div><div class="site slogan"><span class="title">Nice Things</span></div></section><div id="content"><div class="article-container"><section class="article header">
    <h1 class="article title">分布式文件系统HDFS</h1><p class="article date">2020-04-22</p></section><article class="article markdown-body"><h1 id="分布式文件系统hdfs">分布式文件系统HDFS</h1>
<p><code>HDFS（Hadoop Distributed File System）</code>是一个分布式文件系统，用于存储文件。为各类分布式运算框架（MapReduce，Spark，Tez，Flink，…）提供数据存储服务。HDFS通过统一的命名空间——目录树来定位文件，文件系统会给客户端提供一个统一的抽象目录树，客户端通过路径来访问文件，形如：hdfs://hadoop02:9000/soft/hadoop-2.6.5-centos-6.7.tar.gz</p>
<p>HDFS将大文件切割为小数据块，分别存储在不同的机器上联合管理，每个数据块做冗余备份分散到不同服务器，做到高可靠性。</p>
<h2 id="hdfs相关概念和特性">HDFS相关概念和特性</h2>
<p><strong>块</strong>：HDFS 中的文件在物理上是分块存储（block），块的大小可以通过配置参数(dfs.blocksize)来规定，HDFS的一个块要比普通文件系统的块大得多，默认大小在 hadoop2.x 版本中是 128M，老版本中是 64M。较小的块会增加寻址开销；MapReduce以块为单位处理数据，块较大时无法发挥分布式并行处理的效果。</p>
<p><strong>NameNode名称节点</strong>：整个HDFS集群的管家，名称节点负责存储管理元数据。<br>
数据文件会被分为块存储在HDFS上，元数据记录了：（1）文件是什么；（2）文件被分为多少块；（3）每个块和文件是怎么映射的；（4）每个块被存储在哪个服务器上。</p>
<p><strong>DataNode数据节点</strong>：负责存储实际数据。</p>
<p><strong>SecondaryNameNode第二名称节点</strong>，是名称节点的冷备份，同时对EditLog进行处理。</p>
<div align=center><img src="/bdimg/hdfs架构.png" width = "60%" /></div>
<p>HDFS特性：兼容廉价的硬件设备；实现流数据读写；支持大数据集；支持简单的文件模型；强大的跨平台兼容性。<br>
局限性：不适合低延时数据访问；无法高效存储大规模小文件；不支持多用户写入及任意文件修改。</p>
<h2 id="hdfs-核心设计">HDFS 核心设计</h2>
<p><strong>冗余存储机制</strong>，HDFS底层构建在廉价PC机上，容易发生故障，因此采用冗余数据保存，数据块默认保存3份。好处：</p>
<ul>
<li>加快数据传输速度，同样的数据块保存在不同机器上，多个程序同时访问时可以并行在不同机器上获取数据。</li>
<li>保证数据可靠性，当一个副本发生故障，系统探测到后会自动复制副本达到设定数量。</li>
</ul>
<p>修改默认副本数：hdfs-site.xml中的<code>dfs.replication</code>。或<code>bin/hadoop fs -setrep -R num /</code></p>
<p>数据出错：采用校验码机制，数据创建时会对每个数据块生成校验码，同数据块存放在一起，客户端读取数据时同时读取校验码进行计算，如果不一致则说明数据出错。</p>
<p><strong>副本存放策略2.x版本</strong><br>
块的第一个副本：本地机器请求则直接存储在发起请求的机器上，节省数据传输；若是集群外部发起请求则随机选择一个磁盘不满，CPU不忙的机器。<br>
第二个副本：放置在第一个副本相同机架上的不同机器。第三个副本放置在与第一个副本不同机架的机器上。其他副本随机存储。<br>
读数据时，为了降低整体的网络带宽消耗和数据读取延时，让客户端尽量去读取近的副本。1、如果在本机有数据，那么直接读取。2、如果在跟本机同机架的服务器节点中有该数据块，则直接读取。</p>
<p><strong>Hadoop 心跳机制（heartbeat）</strong><br>
Hadoop 是 Master/Slave 结构，Master 启动的时候会启动一个 IPC（Inter-Process Comunication，进程间通信）server 服务，等待 slave 的链接。Slave 启动时，会主动链接 master 的 ipc server 服务，并且每隔 3（参数为 dfs.heartbeat.interval）秒链接一次 master。Slave 通过心跳汇报自己的信息给 master，master 也通过心跳给 slave 下达命令。<br>
当一段时间后没有收到某一数据节点信息则名称节点将其标记为宕机，并将根据元数据将存放在该数据节点的数据通过其他副本，复制分发到其他机器上。<br>
HDFS 默认的超时时间为 10 分钟+30 秒。<br>
<code>timeout = 2 * heartbeat.recheck.interval + 10 * dfs.heartbeat.interval</code>
hdfs-site.xml 配置文件中的 heartbeat.recheck.interval 的单位为毫秒，dfs.heartbeat.interval 的单位为秒</p>
<p><strong>负载均衡</strong><br>
机器与机器之间磁盘利用率不平衡是 HDFS 集群非常容易出现的情况
尤其是在 DataNode 节点出现故障，或在现有的集群上增添新的 DataNode 时。<br>
命令：<code>sbin/start-balancer.sh</code><br>
自动进行均衡非常慢，一天能移动的数据量在 10G-10T 的级别，很难满足超大集群的需求</p>
<h2 id="高可用ha">高可用HA</h2>
<p>在 Hadoop 2.0 之前，存在单点故障 (SPOF：A single point of failure)。对于只有一个 NameNode 的集群，如果 NameNode 机器出现故障(比如宕机或是软件、硬件升级)，那么整个集群将无法使用，直到 NameNode 重新启动。</p>
<p>HDFS 的 HA 功能通过配置 Active/Standby 两个 NameNodes 实现在集群中对 NameNode 的热备来解决上述问题。出现故障时可通过此种方式将 NameNode 很快的切换到另外一台机器。一个典型的 HDFS(HA) 集群中，使用两台单独的机器配置为 NameNodes 。在任何时间点，确保 NameNodes 中只有一个处于 Active 状态，其他的处在 Standby 状态。其中ActiveNameNode 负责集群中的所有客户端操作，StandbyNameNode 仅仅充当备机，保证一旦 ActiveNameNode 出现问题能够快速切换。</p>
<p>为了能够实时同步 Active 和 Standby 两个 NameNode 的元数据信息（实际上 editlog），需提供一个共享存储系统，可以是 NFS、QJM（Quorum Journal Manager）或者 Zookeeper，ActiveNamenode 将数据写入共享存储系统，而 Standby 监听该系统，一旦发现有新数据写入，则读取这些数据，并加载到自己内存中，以保证自己内存状态与 Active NameNode 保持基本一致。</p>
<h2 id="hadoop-fedaration联邦">Hadoop Fedaration联邦</h2>
<p>HDFS Federation 是指 HDFS 集群可同时存在多个 NameNode。这些 NameNode 分别管理一部分数据，且共享所有 DataNode 的存储资源。优点：</p>
<ul>
<li>
<p>HDFS 集群扩展性。多个 NameNode 分管一部分目录，使得一个集群可以扩展到更多节点，不再像 1.0 中那样由于内存的限制制约文件存储数目。</p>
</li>
<li>
<p>性能更高效。多个 NameNode 管理不同的数据，且同时对外提供服务，将为用户提供更高的读写吞吐率。</p>
</li>
<li>
<p>良好的隔离性。用户可根据需要将不同业务数据交由不同 NameNode 管理，这样不同业务之间影响很小。</p>
</li>
</ul>
<p>HDFS Federation 并不能解决单点故障问题，也就是说，每个 NameNode 都存在在单点故障问题。</p>
<h2 id="元数据管理">元数据管理</h2>
<p>NameNode负责元数据的管理，元数据全部加载在内存中，断电时会造成数据丢失，如果只存储在磁盘中则无法快速响应，因此采用内存+磁盘的存储方式。按存储形式可分为内存元数据和元数据文件两种，分别存在内存和磁盘上。<br>
内存元数据包含所有的元数据信息，向客户端提供读服务。磁盘元数据可分为两个：</p>
<ul>
<li><strong>FsImage</strong>镜像文件，是元数据的一个持久化的检查点，包含Hadoop 文件系统中的所有目录和文件元数据信息，但不包含文件块位置的信息。文件块位置信息只存储在内存中，是在 datanode 加入集群的时候，namenode 询问 datanode 得到的，并且间断的更新。</li>
<li><strong>EditLog</strong>：存放的是 Hadoop 文件系统的所有更改操作（文件创建，删除或修改）的日志，文件系统客户端执行的更改操作首先会被记录到 edits 文件中，（WAL，write ahead log，先写Log，再写内存）。</li>
</ul>
<p>FsImage镜像文件用于元数据持久化，但对HDFS数据进行操作时，直接更新磁盘中的FsImage会造成系统变慢，因为FsImage一般都很大。因此使用EditLog记录FsImage检查时点之后的更新操作。</p>
<p>NameNode 启动的时候，将 fsimage加载到内存中，执行 EditLog 文件中的各项操作，使得内存中的元数据和实际的同步。<br>
正常运行过程中，当客户端对 HDFS 中的文件进行操作时，操作记录首先被记入 EditLog 日志文件中，当客户端操作成功后，相应的元数据会更新到内存元数据中。<br>
但这样在运行中EditLog会越来越大，并且在重启后的合并操作也会耗费很长时间。因此要定期的合并FsImage和EditLog，这个工作NameNode来做的话会浪费内存，增加NameNode负担，因此将合并文件的操作在SecondaryNameNode中进行，即<em>CheckPoint</em>操作。</p>
<div align=center><img src="/bdimg/secon机制.png" width = "60%" /></div>
<p>第二名称节点会定期和名称节点进行通信，达到触发CheckPoint条件后，进行CheckPoint。首先请求名称节点停止使用EditLog，名称节点会生成EditLog.new继续记录。第二名称节点会通过Http Get方式下载FsImage和EditLog到本地并加载到内存进行合并，生成一个新的FsImage.ckpt发送给名称节点。名称节点会把EditLog.new更改为EditLog，FsImage.ckpt更改为FsImage，至此刚好是一个轮回。这样即实现了冷备份和元数据持久化。</p>
<p><strong>Checkpoint 触发条件</strong><br>
受两个参数控制，可以通过 core-site.xml 进行配置：</p>
<ul>
<li><code>dfs.namenode.checkpoint.period</code>，checkpoint 之间的最大时间间隔，默认是3600即一小时</li>
<li><code>dfs.namenode.checkpoint.txns</code>，最大的没有执行checkpoint 事务的数量，默认100万条。 
注：旧版为设置fs.checkpoint.period和fs.checkpoint.size（EditLog大小）。</li>
</ul>
<p><strong>配置了HA的元数据管理</strong>
Hadoop 2.x HA架构：</p>
<div align=center><img src="/bdimg/ha架构.png" width = "60%" /></div>
<p>HA架构解决了单点故障问题，同时借助共享存储系统来进行元数据的同步，共享存储系统类型一般有几类，如：Shared NAS+NFS、BookKeeper、BackupNode 和 Quorum Journal Manager(QJM)，上图中用的是QJM作为共享存储组件。<br>
基于 QJM 的共享存储系统主要用于保存 EditLog，FSImage 文件还是在 NameNode 的本地磁盘上。QJM 共享存储的基本思想来自于 Paxos 算法 ，采用多个称为 JournalNode 的节点组成的 JournalNode 集群来存储 EditLog。<br>
Active NameNode 首先把 EditLog 提交到 JournalNode 集群，SNN会定期将本地FSImage和从QJM上拉回的ANN的EditLog进行合并，合并完后再通过RPC传回ANN。即CheckPoint通过SNN实现。  <a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html"target="_blank">参考文章</a></p>
<h2 id="hdfs的shell操作">HDFS的shell操作</h2>
<p>常用命令（添加了环境变量），注：/等同于 配置的hdfs://名称:9000/，即根路径，如果不加/或hdfs:/&hellip;/，则是用户目录/usr/用户名/。</p>
<ul>
<li><code>-help</code>，输出这个命令参数手册； hadoop fs -help ls</li>
<li><code>-ls </code>，显示目录信息；hadoop fs -ls <src></li>
<li><code>-mkdir</code>，hdfs上创建目录；hadoop fs -mkdir -p /aa/bb</li>
<li><code>-put</code>，等同于 copyFromLocal，进行文件上传；hadoop fs -put /aaa/jdk.tar.gz /bbb/jdk.tar.gz</li>
<li><code>-get</code>，等同于 copyToLocal，就是从 hdfs 下载文件到本地；hadoop fs -get /aaa/jdk.tar.gz</li>
<li><code>-getmerge</code>，合并下载多个文件</li>
<li><code>-cp</code>，从 hdfs 的一个路径拷贝 hdfs 的另一个路径；hadoop fs -cp /aaa/jdk.tar.gz /bbb/jdk.tar.gz</li>
<li><code>-mv</code>，在 hdfs 目录中移动文件；hadoop fs -mv /aaa/jdk.tar.gz /</li>
<li><code>-rm</code>，删除文件或文件夹；hadoop fs -rm -r /aaa/bbb/</li>
<li><code>-rmdir</code>，删除空目录；hadoop fs -rmdir /aaa/bbb/ccc</li>
<li><code>-moveFromLocal</code>，<code>-moveToLocal</code>从本地剪切到 hdfs，从 hdfs 剪切到本地</li>
<li><code>-copyFromLocal</code>，<code>-copyToLocal</code>，从本地拷贝文件到 hdfs，从 hdfs 拷贝到本地</li>
<li><code>-appendToFile</code>，追加一个文件到已经存在的文件末尾；hadoop fs -appendToFile ./hello.txt /hello.txt</li>
<li><code>-cat</code>，显示文件内容；<code>-tail</code>，显示一个文件的末尾</li>
<li><code>-text</code>，以字符形式打印一个文件的内容</li>
<li><code>-chgrp</code>,<code>-chmod</code>,<code>-chown</code>，linux 文件系统中的用法一样，对文件所属权限</li>
<li><code>-df</code>，统计文件系统的可用空间信息hadoop fs -df -h /</li>
<li><code>-du</code>，统计文件夹的大小信息hadoop fs -du -s -h /aaa/*</li>
<li><code>-count</code>，统计一个指定目录下的文件节点数量</li>
</ul>
<h2 id="hdfs-的-java-api-操作">HDFS 的 Java API 操作</h2>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.FileSystem</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="o">;</span>
</code></pre></div><p><strong>FileSystem实例</strong><br>
在 java 中操作 hdfs，首先要获得一个客户端实例。Hadoop文件系统通过Hadoop Path对象代表文件，可以将路径视为一个Hadoop文件系统URI。获取FileSystem实例有以下几个静态工厂方法：</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">static</span> <span class="n">FileSystem</span> <span class="nf">get</span> <span class="o">(</span><span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="n">FileSystem</span> <span class="nf">get</span> <span class="o">(</span><span class="n">URI</span> <span class="n">uri</span><span class="o">,</span> <span class="n">Configuration</span> <span class="n">conf</span><span class="o">)</span> <span class="kd">throws</span> <span class="n">IOException</span>
<span class="kd">public</span> <span class="kd">static</span> <span class="n">FileSystem</span> <span class="nf">get</span> <span class="o">(</span><span class="n">URI</span> <span class="n">uri</span><span class="o">,</span> <span class="n">Configuration</span> <span class="n">conf</span><span class="o">,</span> <span class="n">String</span> <span class="n">user</span><span class="o">)</span> <span class="k">throw</span> <span class="n">IOException</span>
</code></pre></div><p>Configuration对象封装了客户端或服务器的配置，通过设置配置文件读取路径实现。第一个方法返回默认的文件系统（core-site.xml中指定，没有则使用本地文件系统）。第二个通过给定的URI方案和权限来确定要使用的文件系统，RUI每个给定则返回默认。第三个作为给定用户来访问文件按系统。我们的操作目标是 HDFS，所以获取到的 fs 对象是 DistributedFileSystem 的实例。
常用API：</p>
<ul>
<li><code>fs.makdirs(Path)</code>，建立文件夹</li>
<li><code>fs.copyFromLocalFile(src, dst)</code>，上传文件，src和dst都是Path对象。</li>
<li><code>fs.copyToLocalFile()</code>，下载文件</li>
<li><code>fs.delete(Path, true)</code>，删除文件或文件夹</li>
<li><code>fs.rename(src, renamed)</code>，重命名</li>
<li><code>fs.exists()</code>，查看文件是否存在</li>
</ul>
<h2 id="hdfs-流式数据读写和流程">HDFS 流式数据读写和流程</h2>
<p>相对那些封装好的方法而言的更底层一些的操作方式 上层那些 mapreduce spark 等运算框架，去 hdfs 中获取数据的时候，就是调的这种底层的 API。</p>
<p><strong>HDFS读数据</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">java.io.BufferedReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">java.io.InputStreamReader</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.FileSystem</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.FSDataInputStream</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">ReadDataTest</span><span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">){</span>
        <span class="k">try</span><span class="o">{</span>
            <span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Configuration</span><span class="o">();</span>
            <span class="n">FileSystem</span> <span class="n">fs</span> <span class="o">=</span> <span class="n">FileSystem</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
            <span class="n">Path</span> <span class="n">filename</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="s">&#34;hdfs://localhost:9000/user/hadoop/test.txt&#34;</span><span class="o">);</span>
            <span class="n">FSDataInputStream</span> <span class="n">is</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="na">open</span><span class="o">(</span><span class="n">filename</span><span class="o">);</span>
            <span class="n">BufferedReader</span> <span class="n">d</span> <span class="o">=</span> <span class="k">new</span> <span class="n">BufferedReader</span><span class="o">(</span><span class="k">new</span> <span class="n">InputStreamReader</span><span class="o">(</span><span class="n">is</span><span class="o">));</span>
            <span class="n">String</span> <span class="n">content</span> <span class="o">=</span> <span class="n">d</span><span class="o">.</span><span class="na">readLine</span><span class="o">();</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="n">content</span><span class="o">);</span>
            <span class="n">d</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
            <span class="n">fs</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><code>FSDataInputStream对象</code>，FileSystem的open()方法返回的是FSDataInputStream对象，是继承了java.io.DataInputStream的特殊类，支持随机访问可从流的任意位置读取数据。</p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kd">public</span> <span class="kd">class</span> <span class="nc">FSDataInputStream</span> <span class="kd">extends</span> <span class="n">DataInputStream</span> <span class="kd">implements</span> <span class="n">Seekable</span><span class="o">,</span> <span class="n">PositionedReadable</span><span class="o">{}</span>
</code></pre></div><ul>
<li>seek()可以移动到文件的任意一个绝对位置；</li>
<li>getPos()查询当前位置相对于文件起始位置的偏移量。</li>
<li>read(long position, byte[] buffer, int offset, int length),从指定position位置处读取至多为length字节的数据存入缓冲区buffer的指定偏移量offset处。</li>
</ul>
<div align=center><img src="/bdimg/hdfs读数据.png" width = "80%" /></div> 
<ol>
<li>使用 HDFS 提供的客户端 Client，向远程的 Namenode 发起 RPC 请求。</li>
<li>Namenode 会视情况返回文件的全部 block 列表，对于每个 block，Namenode 都会返回有该 block 拷贝的 DataNode 地址。</li>
<li>客户端 Client 会选取离客户端最近的 DataNode 来读取 block；如果客户端本身就是DataNode，那么将从本地直接获取数据。</li>
<li>读取完当前 block 的数据后，关闭当前的 DataNode 链接，并为读取下一个 block 寻找最佳的 DataNode。</li>
<li>当读完列表 block 后，且文件读取还没有结束，客户端会继续向 Namenode 获取下一批的 block 列表。</li>
<li>读取完一个 block 都会进行 checksum 验证，如果读取 datanode 时出现错误，客户端会通知 Namenode，然后再从下一个拥有该 block 拷贝的 datanode 继续读。</li>
</ol>
<p><strong>写数据</strong></p>
<div class="highlight"><pre class="chroma"><code class="language-java" data-lang="java"><span class="kn">import</span> <span class="nn">org.apache.hadoop.conf.Configuration</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.FileSystem</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.Path</span><span class="o">;</span>
<span class="kn">import</span> <span class="nn">org.apache.hadoop.fs.FSDataOutputStream</span><span class="o">;</span>

<span class="kd">public</span> <span class="kd">class</span> <span class="nc">WriteDataTest</span><span class="o">{</span>
    <span class="kd">public</span> <span class="kd">static</span> <span class="kt">void</span> <span class="nf">main</span><span class="o">(</span><span class="n">String</span><span class="o">[]</span> <span class="n">args</span><span class="o">){</span>
        <span class="k">try</span><span class="o">{</span>
            <span class="n">Configuration</span> <span class="n">conf</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Configuration</span><span class="o">();</span>
            <span class="n">FileSystem</span> <span class="n">fs</span> <span class="o">=</span> <span class="n">FileSystem</span><span class="o">.</span><span class="na">get</span><span class="o">(</span><span class="n">conf</span><span class="o">);</span>
            <span class="n">Path</span> <span class="n">file</span> <span class="o">=</span> <span class="k">new</span> <span class="n">Path</span><span class="o">(</span><span class="s">&#34;hdfs://localhost:9000/user/hadoop/test.txt&#34;</span><span class="o">);</span>
            <span class="n">FSDataOutputStream</span> <span class="n">outStream</span> <span class="o">=</span> <span class="n">fs</span><span class="o">.</span><span class="na">create</span><span class="o">(</span><span class="n">file</span><span class="o">);</span>
            <span class="n">outStream</span><span class="o">.</span><span class="na">writeUTF</span><span class="o">(</span><span class="s">&#34;Welcome to HDFS Java API!!!&#34;</span><span class="o">);</span>
            <span class="n">System</span><span class="o">.</span><span class="na">out</span><span class="o">.</span><span class="na">println</span><span class="o">(</span><span class="s">&#34;Created!&#34;</span><span class="o">);</span>
            <span class="n">outStream</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
            <span class="n">fs</span><span class="o">.</span><span class="na">close</span><span class="o">();</span>
        <span class="o">}</span> <span class="k">catch</span> <span class="o">(</span><span class="n">Exception</span> <span class="n">e</span><span class="o">)</span> <span class="o">{</span>
            <span class="n">e</span><span class="o">.</span><span class="na">printStackTrace</span><span class="o">();</span>
        <span class="o">}</span>
    <span class="o">}</span>
<span class="o">}</span>
</code></pre></div><p><code>FSDataOutputStream对象</code>，FileSystem的create()和append()（追加）方法返回FSDataOutputStream对象。FSDataOutputStream类不允许在文件中定位，因为HDFS只允许在一个已打开的文件中顺序写入。</p>
<div align=center><img src="/bdimg/HDFS写数据.png" width = "80%" /></div>
<ol>
<li>使用 HDFS 提供的客户端 Client，向远程的 Namenode 发起 RPC 请求。</li>
<li>Namenode检查文件是否已经存在，是否有权限进行操作，成功则会为文件创建一个记录，否则会让客户端抛出异常。</li>
<li>客户端开始写入文件时，会将文件切分成多个 packets，并在内部以数据队列“data queue”的形式管理这些 packets，向 Namenode 申请 blocks，获取用来存储replicas 的合适的 datanode 列表，列表的大小根据 Namenode 中 replication的设定而定。</li>
<li>开始以 pipeline（管道）的形式将 packet 写入所有的 replicas 中。客户端把 packet 以流的方式写入第一个 datanode，该 datanode 把该 packet 存储之后，再将其传递给在此 pipeline中的下一个 datanode，直到最后一个 datanode，这种写数据的方式呈流水线的形式。</li>
<li>最后一个 datanode 成功存储之后会返回一个 ack packet（确认队列），在 pipeline 里传递至客户端，在客户端的开发库内部维护着&quot;ack queue&rdquo;，成功收到 datanode 返回的 ack packet 后会从&quot;ack queue&quot;移除相应的 packet。</li>
<li>如果传输过程中某个 datanode 出现故障，那么当前的 pipeline 会被关闭，出现故障的 datanode 会从当前的 pipeline 中移除，剩余的 block 会继续剩下的 datanode 中继续以 pipeline 的形式传输，同时 Namenode 会分配一个新的 datanode，保持 replicas 设定的数量。</li>
<li>客户端完成数据的写入后，会对数据流调用 close()方法，关闭数据流。</li>
<li>只要写入了 dfs.replication.min(最小)的复本数（默认为 1），写操作就会成功，并且这个块可以在集群中异步复制，直到达到其目标复本数（dfs．replication 的默认值为 3），因为 namenode 已经知道文件由哪些块组成，所以它在返回成功前只需要等待数据块进行最小量的复制。</li>
</ol>
<p>参考：<br>
[1] <a href="https://www.icourse163.org/course/XMU-1002335004"target="_blank">大数据技术原理与应用Mooc</a>.<br>
[2] 光环国际课件.<br>
[3] <a href="https://blog.csdn.net/qq_33624952/article/details/79341477">https://blog.csdn.net/qq_33624952/article/details/79341477</a><br>
[4] <a href="https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html">https://www.ibm.com/developerworks/cn/opensource/os-cn-hadoop-name-node/index.html</a><br>
[5] <a href="https://blog.csdn.net/kkdelta/article/details/50393413">https://blog.csdn.net/kkdelta/article/details/50393413</a><br>
[6] <a href="https://my.oschina.net/gordonnemo/blog/3017724">https://my.oschina.net/gordonnemo/blog/3017724</a></p>
</article><section class="article labels"><a class="category" href=/categories/%E5%A4%A7%E6%95%B0%E6%8D%AE/>大数据</a><a class="tag" href=/tags/hadoop/>Hadoop</a><a class="tag" href=/tags/hdfs/>HDFS</a></section></div><section class="article navigation"><p><a class="link" href="/post/yarn/"><span class="li">&larr;</span>Hdoop资源管理系统YARN</a></p><p><a class="link" href="/post/%E5%A4%A7%E6%95%B0%E6%8D%AEhadoop/"><span class="li">&rarr;</span>大数据和Hadoop</a></p></section></div><section id="footer" class="footer"><div class="footer-wrap">
    <p class="copyright">©2020 Notepadium.</p>
    <p class="powerby"><span>Powered by </span><a href="https://gohugo.io" 
        target="_blank">Hugo</a><span> and the </span><a href="https://themes.gohugo.io/hugo-notepadium/" 
        target="_blank">Notepadium</a></p>
</div></section><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/&#43;DiW/UqRcLbRjq" crossorigin="anonymous"><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l&#43;B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd&#43;qj&#43;o24G5ZU2zJz" crossorigin="anonymous"></script><script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"
            onload="renderMathInElement(document.body);"></script></div>
</body>

</html>